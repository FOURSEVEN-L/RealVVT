data:
  train_bs: 2
  train_width: 384
  train_height: 512
  meta_paths:
    - "../animate/VideoData/dresses/dresses_train.json"
    - "../animate/VideoData/lower_body/lower_body_train.json"
    - "../animate/VideoData/upper_body/upper_body_train.json"
    - "../animate/VideoData/dresses/dresses_train.json"
    - "../animate/VideoData/lower_body/lower_body_train.json"
    - "../animate/VideoData/upper_body/upper_body_train.json"
    - "../animate/VideoData/dresses/dresses_train.json"
    - "../animate/VideoData/lower_body/lower_body_train.json"
    - "../animate/VideoData/upper_body/upper_body_train.json"
    - "../animate/VideoData/dresses/dresses_train.json"
    - "../animate/VideoData/lower_body/lower_body_train.json"
    - "../animate/VideoData/upper_body/upper_body_train.json"
    - "../animate/DressCode/dresses/train.json"
    - "../animate/DressCode/lower_body/train.json"
    - "../animate/DressCode/upper_body/train.json"
    - "../animate/VITON-HD/train/train_path.json"
  # Margin of frame indexes between ref and tgt images
  sample_rate: 10 
  n_sample_frames: 16
  obpos_loss_weight: 0.5
  obneg_loss_weight: 0.005
  num_workers: 4
  fps: 7
  motion_bucket_id: 40

noise_scheduler:
  P_mean: 0.7
  P_std: 1.6
  sigma_data: 1

val_data:
  infer_width: 624
  infer_height: 832
  num_frames: 16
  decode_chunk_size: 8
  motion_bucket_id: 40
  fps: 7
  noise_aug_strength: 0.02
  num_inference_steps: 25
  min_guidance_scale: 1.0
  max_guidance_scale: 3.0
  tile_size: 16
  tile_overlap: 2
  ref_images:
    - "../animate/VideoData/dresses/images/1241204_in_xl.jpg"
  drive_poses:
    - "../animate/VideoData/dresses/densepose/1241207_detail.mp4"
  pixel_values:
    - "../animate/VideoData/dresses/videos/1241207_detail.mp4"
  pixel_values_video_mask:
    - "../animate/VideoData/dresses/agnostic_mask/1241207_detail.mp4"
  pixel_agnostic:
    - "../animate/VideoData/dresses/agnostic/1241207_detail.mp4"
solver:
  gradient_accumulation_steps: 1
  mixed_precision: 'fp16'
  enable_xformers_memory_efficient_attention: False
  gradient_checkpointing: True 
  max_train_steps: 100000
  
  max_grad_norm: 1.0
  # lr
  learning_rate: 5.0e-5
  scale_lr: False 
  lr_warmup_steps: 500
  lr_scheduler: 'constant'

  # optimizer
  use_8bit_adam: False
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_weight_decay:  1.0e-2
  adam_epsilon: 1.0e-8

allow_tf32: True
total_limit: 20
save_model_epoch_interval: 20
use_ema: False
random_null_ratio: 0.05
target_ema_decay: 0.99
checkpointing_steps: 1500
pretrained_model_name_or_path: "../pretrained_weights/stable-video-diffusion-img2vid-xt"
pretrained_sd_model_name_or_path: "../pretrained_weights/stable-diffusion-2-1"


reference_net_checkpoint_path: ""
unet_checkpoint_path: ""
pose_guider_checkpoint_path: ""
resume_from_checkpoint: False
pose_guider_pretrain: False

seed: 1234
exp_name: 'lr_5_5_xt_16frames_384x512_bs2'
output_dir: '../animate/exp_outs_34'  
